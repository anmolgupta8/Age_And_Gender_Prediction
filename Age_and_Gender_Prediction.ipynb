{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FD9CJDoVi9Gz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from tqdm.notebook import tqdm\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "# from keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import load_img\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoVgUz5wsRgH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "! unzip '/content/drive/MyDrive/Age_And_Gender_Detection_Dataset/UTKFace.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qBcFEUuQlgsv"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = '/content/UTKFace'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjNgqKl6mZW9"
      },
      "outputs": [],
      "source": [
        "# labels - age, gender, ethnicity\n",
        "image_paths = []\n",
        "age_labels = []\n",
        "gender_labels = []\n",
        "\n",
        "for filename in tqdm(os.listdir(BASE_DIR)):\n",
        "    image_path = os.path.join(BASE_DIR, filename)\n",
        "    temp = filename.split('_')\n",
        "    age = int(temp[0])\n",
        "    gender = int(temp[1])\n",
        "    image_paths.append(image_path)\n",
        "    age_labels.append(age)\n",
        "    gender_labels.append(gender)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zq6Nyhfvmdsm"
      },
      "outputs": [],
      "source": [
        "# convert to dataframe\n",
        "df = pd.DataFrame()\n",
        "df['image'], df['age'], df['gender'] = image_paths, age_labels, gender_labels\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vMh7jF-Gt8Op"
      },
      "outputs": [],
      "source": [
        "# map labels for gender\n",
        "gender_dict = {0:'Male', 1:'Female'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQ0mdIQBt_h2"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "img = Image.open(df['image'][0])\n",
        "plt.axis('off')\n",
        "plt.imshow(img);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5zZ4KD9uHP0"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df['age'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xAzABNqnuJ3_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# to display grid of images\n",
        "plt.figure(figsize=(20, 20))\n",
        "files = df.iloc[0:25]\n",
        "\n",
        "for index, file, age, gender in files.itertuples():\n",
        "    plt.subplot(5, 5, index+1)\n",
        "    img = load_img(file)\n",
        "    img = np.array(img)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Age: {age} Gender: {gender_dict[gender]}\")\n",
        "    plt.axis('off')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BKhfVpOOuUU_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def extract_features(images):\n",
        "    features = []\n",
        "    for image in tqdm(images):\n",
        "        img = load_img(image, grayscale=True)\n",
        "        img = img.resize((128, 128), Image.ANTIALIAS)\n",
        "        img = np.array(img)\n",
        "        features.append(img)\n",
        "\n",
        "    features = np.array(features)\n",
        "    # ignore this step if using RGB\n",
        "    features = features.reshape(len(features), 128, 128, 1)\n",
        "    return features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJpiBd9JuXEM"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "X = extract_features(df['image'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NhfowX3u078"
      },
      "outputs": [],
      "source": [
        "\n",
        "X.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HyRM4k2Bu6Su"
      },
      "outputs": [],
      "source": [
        "# normalize the images\n",
        "X = X/255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "vUwrI--wu_Tl"
      },
      "outputs": [],
      "source": [
        "y_gender = np.array(df['gender'])\n",
        "y_age = np.array(df['age'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MuJgeLDbvKC3"
      },
      "outputs": [],
      "source": [
        "input_shape = (128, 128, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "TuhVvpcYvNQH"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "inputs = Input((input_shape))\n",
        "# convolutional layers\n",
        "conv_1 = Conv2D(32, kernel_size=(3, 3), activation='relu') (inputs)\n",
        "maxp_1 = MaxPooling2D(pool_size=(2, 2)) (conv_1)\n",
        "conv_2 = Conv2D(64, kernel_size=(3, 3), activation='relu') (maxp_1)\n",
        "maxp_2 = MaxPooling2D(pool_size=(2, 2)) (conv_2)\n",
        "conv_3 = Conv2D(128, kernel_size=(3, 3), activation='relu') (maxp_2)\n",
        "maxp_3 = MaxPooling2D(pool_size=(2, 2)) (conv_3)\n",
        "conv_4 = Conv2D(256, kernel_size=(3, 3), activation='relu') (maxp_3)\n",
        "maxp_4 = MaxPooling2D(pool_size=(2, 2)) (conv_4)\n",
        "\n",
        "flatten = Flatten() (maxp_4)\n",
        "\n",
        "# fully connected layers\n",
        "dense_1 = Dense(256, activation='relu') (flatten)\n",
        "dense_2 = Dense(256, activation='relu') (flatten)\n",
        "\n",
        "dropout_1 = Dropout(0.3) (dense_1)\n",
        "dropout_2 = Dropout(0.3) (dense_2)\n",
        "\n",
        "output_1 = Dense(1, activation='sigmoid', name='gender_out') (dropout_1)\n",
        "output_2 = Dense(1, activation='relu', name='age_out') (dropout_2)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[output_1, output_2])\n",
        "\n",
        "model.compile(loss=['binary_crossentropy', 'mae'], optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bivppgh0vTKl"
      },
      "outputs": [],
      "source": [
        "# plot the model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwE8GP5NvZF6"
      },
      "outputs": [],
      "source": [
        "# train model\n",
        "history = model.fit(x=X, y=[y_gender, y_age], batch_size=32, epochs=20, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieu-G7Zp6QTd"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# plot results for gender\n",
        "acc = history.history['gender_out_accuracy']\n",
        "val_acc = history.history['val_gender_out_accuracy']\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')\n",
        "plt.title('Accuracy Graph')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "loss = history.history['gender_out_loss']\n",
        "val_loss = history.history['val_gender_out_loss']\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Loss Graph')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4K7xKWp6XCH"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# plot results for age\n",
        "loss = history.history['age_out_loss']\n",
        "val_loss = history.history['val_age_out_loss']\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Loss Graph')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UtJZ4w-6dHD"
      },
      "outputs": [],
      "source": [
        "image_index = np.random.randint(0,23707)\n",
        "print(image_index)\n",
        "print(\"Original Gender:\", gender_dict[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n",
        "# predict from model\n",
        "pred = model.predict(X[image_index].reshape(1, 128, 128, 1))\n",
        "pred_gender = gender_dict[round(pred[0][0][0])]\n",
        "pred_age = round(pred[1][0][0])\n",
        "print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n",
        "plt.axis('off')\n",
        "plt.imshow(X[image_index].reshape(128, 128), cmap='gray');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-PKkLjh6mRX"
      },
      "outputs": [],
      "source": [
        "image_index = np.random.randint(0,23707)\n",
        "print(image_index)\n",
        "print(\"Original Gender:\", gender_dict[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n",
        "# predict from model\n",
        "pred = model.predict(X[image_index].reshape(1, 128, 128, 1))\n",
        "pred_gender = gender_dict[round(pred[0][0][0])]\n",
        "pred_age = round(pred[1][0][0])\n",
        "print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n",
        "plt.axis('off')\n",
        "plt.imshow(X[image_index].reshape(128, 128), cmap='gray');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM0ZDTbj6rgC"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "image_index = np.random.randint(0,23708)\n",
        "print(image_index)\n",
        "print(\"Original Gender:\", gender_dict[y_gender[image_index]], \"Original Age:\", y_age[image_index])\n",
        "# predict from model\n",
        "pred = model.predict(X[image_index].reshape(1, 128, 128, 1))\n",
        "pred_gender = gender_dict[round(pred[0][0][0])]\n",
        "pred_age = round(pred[1][0][0])\n",
        "print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n",
        "plt.axis('off')\n",
        "plt.imshow(X[image_index].reshape(128, 128), cmap='gray');\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3R9C_lfl60jS"
      },
      "outputs": [],
      "source": [
        "#testing\n",
        "test = np.random.randint(0,23707,3000)\n",
        "age=0\n",
        "gender=0\n",
        "combined=0\n",
        "for i in test:\n",
        "    image_index = i\n",
        "    orig_gender=gender_dict[y_gender[image_index]]\n",
        "    orig_age=y_age[image_index]\n",
        "    pred = model.predict(X[image_index].reshape(1, 128, 128, 1),verbose=0)\n",
        "    pred_gender = gender_dict[round(pred[0][0][0])]\n",
        "    pred_age = round(pred[1][0][0])\n",
        "    if abs(pred_age-orig_age)<=8:\n",
        "        age+=1\n",
        "    if pred_gender==orig_gender:\n",
        "        gender+=1\n",
        "    if abs(pred_age-orig_age)<=5 and pred_gender==orig_gender:\n",
        "        combined+=1\n",
        "print(age,gender,combined)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0_OBpej-EeV"
      },
      "outputs": [],
      "source": [
        "def get_image_features(image):\n",
        "  img = load_img(image, grayscale=True)\n",
        "  img = img.resize((128, 128), Image.ANTIALIAS)\n",
        "  img = np.array(img)\n",
        "  img = img.reshape(1, 128, 128, 1)\n",
        "  img = img / 255.0\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG-AmRFR_xT8"
      },
      "outputs": [],
      "source": [
        "# img_to_test = '/Image.png'\n",
        "features = get_image_features(img_to_test)\n",
        "pred = model.predict(features)\n",
        "\n",
        "pred_gender = gender_dict[round(pred[0][0][0])]\n",
        "pred_age = round(pred[1][0][0])\n",
        "print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n",
        "plt.axis('off')\n",
        "plt.imshow(np.array(load_img(img_to_test)), cmap='gray');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hs1wOdgjCW_a"
      },
      "outputs": [],
      "source": [
        "# img_to_test = '/Image.png'\n",
        "features = get_image_features(img_to_test)\n",
        "pred = model.predict(features)\n",
        "\n",
        "pred_gender = gender_dict[round(pred[0][0][0])]\n",
        "pred_age = round(pred[1][0][0])\n",
        "print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n",
        "plt.axis('off')\n",
        "plt.imshow(np.array(load_img(img_to_test)), cmap='gray');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbZE8jkPCavL"
      },
      "outputs": [],
      "source": [
        "# img_to_test = '/Image.png'\n",
        "features = get_image_features(img_to_test)\n",
        "pred = model.predict(features)\n",
        "\n",
        "pred_gender = gender_dict[round(pred[0][0][0])]\n",
        "pred_age = round(pred[1][0][0])\n",
        "print(\"Predicted Gender:\", pred_gender, \"Predicted Age:\", pred_age)\n",
        "plt.axis('off')\n",
        "plt.imshow(np.array(load_img(img_to_test)));"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}